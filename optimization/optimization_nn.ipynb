{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "import mlrose_hiive\n",
    "\n",
    "# Models\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from utils import learning_curve_plotter, model_param_curve, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base param\n",
    "seed = 712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "diabet_path = \"./data/diabetes.csv\"\n",
    "df_diabet = pd.read_csv(diabet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diabet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0          500\n",
      "1          268\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize target value\n",
    "\n",
    "target_cnt = df_diabet[[\"Outcome\"]].value_counts()\n",
    "print(target_cnt)\n",
    "\n",
    "target_cnt.plot(kind='barh', title=\"Target Value Count\")\n",
    "plt.xlabel(\"diabet\")\n",
    "plt.ylabel(\"examples\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0          0.651042\n",
       "1          0.348958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cnt / len(df_diabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Outcome'\n",
    "features = [ 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "train_df, test_df = train_test_split(df_diabet, test_size=0.2, random_state=712)\n",
    "X_train_origin, y_train = train_df[features], train_df[target]\n",
    "X_test_origin, y_test = test_df[features], test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalize\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_origin)\n",
    "\n",
    "X_train = sc.transform(X_train_origin)\n",
    "X_test = sc.transform(X_test_origin)\n",
    "\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     print(f\"Range after normalize feature {i}'s {min(X_train_origin[:, i])} ~ {max(X_train_origin[:, i])} to {min(X_train[:, i])} ~ {max(X_train[:, i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent: 1 - duration: 0.00437474250793457, tr_acc: 0.7133550488599348, test_acc: 0.7272727272727273, f1: 0.5\n",
      "gradient_descent: 101 - duration: 0.1352698802947998, tr_acc: 0.8061889250814332, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 201 - duration: 0.26429200172424316, tr_acc: 0.8110749185667753, test_acc: 0.7727272727272727, f1: 0.6534653465346535\n",
      "gradient_descent: 301 - duration: 0.3833279609680176, tr_acc: 0.8208469055374593, test_acc: 0.7337662337662337, f1: 0.594059405940594\n",
      "gradient_descent: 401 - duration: 0.5441350936889648, tr_acc: 0.8338762214983714, test_acc: 0.7727272727272727, f1: 0.6464646464646465\n",
      "gradient_descent: 501 - duration: 0.6471340656280518, tr_acc: 0.8289902280130294, test_acc: 0.7532467532467533, f1: 0.6274509803921569\n",
      "gradient_descent: 601 - duration: 0.7865653038024902, tr_acc: 0.8306188925081434, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 701 - duration: 0.9027087688446045, tr_acc: 0.8517915309446255, test_acc: 0.7402597402597403, f1: 0.607843137254902\n",
      "gradient_descent: 801 - duration: 1.0272231101989746, tr_acc: 0.8485342019543974, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 901 - duration: 1.1843972206115723, tr_acc: 0.8485342019543974, test_acc: 0.7402597402597403, f1: 0.6296296296296295\n",
      "gradient_descent: 1001 - duration: 1.3125920295715332, tr_acc: 0.8534201954397395, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1101 - duration: 1.4146490097045898, tr_acc: 0.8599348534201955, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 1201 - duration: 1.5526010990142822, tr_acc: 0.8648208469055375, test_acc: 0.7337662337662337, f1: 0.6238532110091743\n",
      "gradient_descent: 1301 - duration: 1.7129929065704346, tr_acc: 0.8713355048859935, test_acc: 0.7337662337662337, f1: 0.6238532110091743\n",
      "gradient_descent: 1401 - duration: 1.8097188472747803, tr_acc: 0.8648208469055375, test_acc: 0.7337662337662337, f1: 0.6238532110091743\n",
      "gradient_descent: 1501 - duration: 1.964648962020874, tr_acc: 0.8648208469055375, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 1601 - duration: 2.063156843185425, tr_acc: 0.8664495114006515, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1701 - duration: 2.151020050048828, tr_acc: 0.8648208469055375, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1801 - duration: 2.3357908725738525, tr_acc: 0.8680781758957655, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 1901 - duration: 2.4684970378875732, tr_acc: 0.8680781758957655, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 2001 - duration: 2.655224084854126, tr_acc: 0.8697068403908795, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 2101 - duration: 2.6754820346832275, tr_acc: 0.8697068403908795, test_acc: 0.7272727272727273, f1: 0.6111111111111112\n",
      "gradient_descent: 2201 - duration: 2.8782970905303955, tr_acc: 0.8713355048859935, test_acc: 0.7207792207792207, f1: 0.5981308411214952\n",
      "gradient_descent: 2301 - duration: 3.012725830078125, tr_acc: 0.8729641693811075, test_acc: 0.7207792207792207, f1: 0.5981308411214952\n",
      "gradient_descent: 2401 - duration: 3.077528715133667, tr_acc: 0.8697068403908795, test_acc: 0.7402597402597403, f1: 0.6296296296296295\n",
      "gradient_descent: 2501 - duration: 3.188368797302246, tr_acc: 0.8745928338762216, test_acc: 0.7272727272727273, f1: 0.6111111111111112\n",
      "gradient_descent: 2601 - duration: 3.3337690830230713, tr_acc: 0.8778501628664495, test_acc: 0.7207792207792207, f1: 0.6126126126126126\n",
      "gradient_descent: 2701 - duration: 3.4311258792877197, tr_acc: 0.8827361563517915, test_acc: 0.7142857142857143, f1: 0.6071428571428571\n",
      "gradient_descent: 2801 - duration: 3.584022045135498, tr_acc: 0.8778501628664495, test_acc: 0.7077922077922078, f1: 0.6017699115044246\n",
      "gradient_descent: 2901 - duration: 3.7957990169525146, tr_acc: 0.8778501628664495, test_acc: 0.7077922077922078, f1: 0.6017699115044246\n",
      "gradient_descent: 3001 - duration: 3.864872932434082, tr_acc: 0.8778501628664495, test_acc: 0.7077922077922078, f1: 0.6017699115044246\n",
      "gradient_descent: 3101 - duration: 3.982569932937622, tr_acc: 0.8778501628664495, test_acc: 0.7077922077922078, f1: 0.6017699115044246\n",
      "gradient_descent: 3201 - duration: 4.102919816970825, tr_acc: 0.8729641693811075, test_acc: 0.7272727272727273, f1: 0.625\n",
      "gradient_descent: 3301 - duration: 4.25911808013916, tr_acc: 0.8745928338762216, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 3401 - duration: 4.38792610168457, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 3501 - duration: 4.527432203292847, tr_acc: 0.8729641693811075, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 3601 - duration: 4.58632493019104, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 3701 - duration: 4.743146896362305, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 3801 - duration: 4.878137111663818, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 3901 - duration: 4.99514102935791, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4001 - duration: 5.157300233840942, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4101 - duration: 5.2758238315582275, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4201 - duration: 5.419023036956787, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4301 - duration: 5.5587687492370605, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4401 - duration: 5.688744068145752, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4501 - duration: 5.925166845321655, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4601 - duration: 5.961091041564941, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4701 - duration: 6.001168966293335, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4801 - duration: 6.161792039871216, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 4901 - duration: 6.458164930343628, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "gradient_descent: 5001 - duration: 6.5668861865997314, tr_acc: 0.8762214983713354, test_acc: 0.7402597402597403, f1: 0.6428571428571429\n",
      "random_hill_climb: 1 - duration: 0.0021800994873046875, tr_acc: 0.3925081433224756, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "random_hill_climb: 101 - duration: 0.09652996063232422, tr_acc: 0.4006514657980456, test_acc: 0.44155844155844154, f1: 0.5057471264367817\n",
      "random_hill_climb: 201 - duration: 0.1976921558380127, tr_acc: 0.41205211726384366, test_acc: 0.44155844155844154, f1: 0.5057471264367817\n",
      "random_hill_climb: 301 - duration: 0.27675580978393555, tr_acc: 0.4153094462540717, test_acc: 0.44805194805194803, f1: 0.5086705202312138\n",
      "random_hill_climb: 401 - duration: 0.3611030578613281, tr_acc: 0.4169381107491857, test_acc: 0.45454545454545453, f1: 0.5058823529411764\n",
      "random_hill_climb: 501 - duration: 0.46457886695861816, tr_acc: 0.42671009771986973, test_acc: 0.474025974025974, f1: 0.5149700598802396\n",
      "random_hill_climb: 601 - duration: 0.5668330192565918, tr_acc: 0.44136807817589574, test_acc: 0.4805194805194805, f1: 0.5180722891566265\n",
      "random_hill_climb: 701 - duration: 0.6504602432250977, tr_acc: 0.44462540716612375, test_acc: 0.474025974025974, f1: 0.509090909090909\n",
      "random_hill_climb: 801 - duration: 0.7321438789367676, tr_acc: 0.4495114006514658, test_acc: 0.4675324675324675, f1: 0.5\n",
      "random_hill_climb: 901 - duration: 0.8061208724975586, tr_acc: 0.4739413680781759, test_acc: 0.4935064935064935, f1: 0.5125000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_hill_climb: 1001 - duration: 0.8872649669647217, tr_acc: 0.49022801302931596, test_acc: 0.5064935064935064, f1: 0.5189873417721519\n",
      "random_hill_climb: 1101 - duration: 0.9869132041931152, tr_acc: 0.501628664495114, test_acc: 0.538961038961039, f1: 0.5359477124183006\n",
      "random_hill_climb: 1201 - duration: 1.0916390419006348, tr_acc: 0.5162866449511401, test_acc: 0.564935064935065, f1: 0.5503355704697986\n",
      "random_hill_climb: 1301 - duration: 1.1658422946929932, tr_acc: 0.5309446254071661, test_acc: 0.577922077922078, f1: 0.5578231292517007\n",
      "random_hill_climb: 1401 - duration: 1.2569141387939453, tr_acc: 0.5488599348534202, test_acc: 0.5909090909090909, f1: 0.5655172413793104\n",
      "random_hill_climb: 1501 - duration: 1.346879005432129, tr_acc: 0.5684039087947883, test_acc: 0.5974025974025974, f1: 0.5633802816901408\n",
      "random_hill_climb: 1601 - duration: 1.4463140964508057, tr_acc: 0.5846905537459284, test_acc: 0.6233766233766234, f1: 0.5797101449275363\n",
      "random_hill_climb: 1701 - duration: 1.5328059196472168, tr_acc: 0.6074918566775245, test_acc: 0.6363636363636364, f1: 0.5882352941176471\n",
      "random_hill_climb: 1801 - duration: 1.6240589618682861, tr_acc: 0.6205211726384365, test_acc: 0.6428571428571429, f1: 0.5925925925925926\n",
      "random_hill_climb: 1901 - duration: 1.7285020351409912, tr_acc: 0.6254071661237784, test_acc: 0.6558441558441559, f1: 0.5954198473282444\n",
      "random_hill_climb: 2001 - duration: 1.7996611595153809, tr_acc: 0.6465798045602605, test_acc: 0.6493506493506493, f1: 0.5781249999999999\n",
      "random_hill_climb: 2101 - duration: 1.920414924621582, tr_acc: 0.6465798045602605, test_acc: 0.6428571428571429, f1: 0.5669291338582677\n",
      "random_hill_climb: 2201 - duration: 2.0699028968811035, tr_acc: 0.6514657980456026, test_acc: 0.6493506493506493, f1: 0.5645161290322581\n",
      "random_hill_climb: 2301 - duration: 2.0973622798919678, tr_acc: 0.6579804560260586, test_acc: 0.6558441558441559, f1: 0.5691056910569107\n",
      "random_hill_climb: 2401 - duration: 2.173985004425049, tr_acc: 0.6612377850162866, test_acc: 0.6623376623376623, f1: 0.5737704918032787\n",
      "random_hill_climb: 2501 - duration: 2.2419958114624023, tr_acc: 0.6644951140065146, test_acc: 0.6688311688311688, f1: 0.5785123966942148\n",
      "random_hill_climb: 2601 - duration: 2.318403720855713, tr_acc: 0.6693811074918566, test_acc: 0.6818181818181818, f1: 0.588235294117647\n",
      "random_hill_climb: 2701 - duration: 2.4169681072235107, tr_acc: 0.6742671009771987, test_acc: 0.7012987012987013, f1: 0.603448275862069\n",
      "random_hill_climb: 2801 - duration: 2.5080902576446533, tr_acc: 0.6742671009771987, test_acc: 0.7272727272727273, f1: 0.6315789473684211\n",
      "random_hill_climb: 2901 - duration: 2.616321086883545, tr_acc: 0.6824104234527687, test_acc: 0.7337662337662337, f1: 0.6371681415929203\n",
      "random_hill_climb: 3001 - duration: 2.706143856048584, tr_acc: 0.6872964169381107, test_acc: 0.7337662337662337, f1: 0.6371681415929203\n",
      "random_hill_climb: 3101 - duration: 2.832836151123047, tr_acc: 0.6872964169381107, test_acc: 0.7402597402597403, f1: 0.6491228070175439\n",
      "random_hill_climb: 3201 - duration: 2.9698681831359863, tr_acc: 0.6872964169381107, test_acc: 0.7337662337662337, f1: 0.6306306306306305\n",
      "random_hill_climb: 3301 - duration: 2.9703288078308105, tr_acc: 0.6905537459283387, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "random_hill_climb: 3401 - duration: 3.085841178894043, tr_acc: 0.6954397394136808, test_acc: 0.7272727272727273, f1: 0.6181818181818182\n",
      "random_hill_climb: 3501 - duration: 3.198875904083252, tr_acc: 0.6954397394136808, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "random_hill_climb: 3601 - duration: 3.3813960552215576, tr_acc: 0.6986970684039088, test_acc: 0.7467532467532467, f1: 0.6355140186915887\n",
      "random_hill_climb: 3701 - duration: 3.4654552936553955, tr_acc: 0.6970684039087948, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "random_hill_climb: 3801 - duration: 3.482090950012207, tr_acc: 0.7068403908794788, test_acc: 0.7337662337662337, f1: 0.6095238095238096\n",
      "random_hill_climb: 3901 - duration: 3.514338970184326, tr_acc: 0.7166123778501629, test_acc: 0.7272727272727273, f1: 0.5961538461538461\n",
      "random_hill_climb: 4001 - duration: 3.598339080810547, tr_acc: 0.7198697068403909, test_acc: 0.7272727272727273, f1: 0.5961538461538461\n",
      "random_hill_climb: 4101 - duration: 3.6760377883911133, tr_acc: 0.7231270358306189, test_acc: 0.7272727272727273, f1: 0.5961538461538461\n",
      "random_hill_climb: 4201 - duration: 3.8181698322296143, tr_acc: 0.7198697068403909, test_acc: 0.7207792207792207, f1: 0.5825242718446603\n",
      "random_hill_climb: 4301 - duration: 3.865431785583496, tr_acc: 0.7280130293159609, test_acc: 0.7272727272727273, f1: 0.5882352941176471\n",
      "random_hill_climb: 4401 - duration: 3.997941017150879, tr_acc: 0.7345276872964169, test_acc: 0.7207792207792207, f1: 0.5742574257425743\n",
      "random_hill_climb: 4501 - duration: 4.1387410163879395, tr_acc: 0.739413680781759, test_acc: 0.7142857142857143, f1: 0.5686274509803921\n",
      "random_hill_climb: 4601 - duration: 4.148105144500732, tr_acc: 0.737785016286645, test_acc: 0.7142857142857143, f1: 0.5686274509803921\n",
      "random_hill_climb: 4701 - duration: 4.174146890640259, tr_acc: 0.741042345276873, test_acc: 0.7142857142857143, f1: 0.5686274509803921\n",
      "random_hill_climb: 4801 - duration: 4.314271926879883, tr_acc: 0.747557003257329, test_acc: 0.7142857142857143, f1: 0.5686274509803921\n",
      "random_hill_climb: 4901 - duration: 4.437303781509399, tr_acc: 0.749185667752443, test_acc: 0.7142857142857143, f1: 0.5686274509803921\n",
      "random_hill_climb: 5001 - duration: 4.490278244018555, tr_acc: 0.758957654723127, test_acc: 0.7207792207792207, f1: 0.5825242718446603\n",
      "simulated_annealing: 1 - duration: 0.002145051956176758, tr_acc: 0.3925081433224756, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "simulated_annealing: 101 - duration: 0.11582207679748535, tr_acc: 0.3925081433224756, test_acc: 0.43506493506493504, f1: 0.5028571428571429\n",
      "simulated_annealing: 201 - duration: 0.24538803100585938, tr_acc: 0.3925081433224756, test_acc: 0.4025974025974026, f1: 0.47727272727272724\n",
      "simulated_annealing: 301 - duration: 0.3645000457763672, tr_acc: 0.3973941368078176, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "simulated_annealing: 401 - duration: 0.4886128902435303, tr_acc: 0.3941368078175896, test_acc: 0.4025974025974026, f1: 0.47727272727272724\n",
      "simulated_annealing: 501 - duration: 0.6088159084320068, tr_acc: 0.3941368078175896, test_acc: 0.4090909090909091, f1: 0.48587570621468923\n",
      "simulated_annealing: 601 - duration: 0.7171599864959717, tr_acc: 0.3925081433224756, test_acc: 0.4025974025974026, f1: 0.48314606741573035\n",
      "simulated_annealing: 701 - duration: 0.8272280693054199, tr_acc: 0.39087947882736157, test_acc: 0.42207792207792205, f1: 0.49142857142857144\n",
      "simulated_annealing: 801 - duration: 0.965846061706543, tr_acc: 0.3973941368078176, test_acc: 0.42857142857142855, f1: 0.49425287356321834\n",
      "simulated_annealing: 901 - duration: 1.0637109279632568, tr_acc: 0.40879478827361565, test_acc: 0.42857142857142855, f1: 0.49425287356321834\n",
      "simulated_annealing: 1001 - duration: 1.1584498882293701, tr_acc: 0.41368078175895767, test_acc: 0.43506493506493504, f1: 0.49710982658959535\n",
      "simulated_annealing: 1101 - duration: 1.2690176963806152, tr_acc: 0.4201954397394137, test_acc: 0.43506493506493504, f1: 0.4912280701754386\n",
      "simulated_annealing: 1201 - duration: 1.3870980739593506, tr_acc: 0.4234527687296417, test_acc: 0.461038961038961, f1: 0.5029940119760479\n",
      "simulated_annealing: 1301 - duration: 1.500173807144165, tr_acc: 0.42996742671009774, test_acc: 0.461038961038961, f1: 0.5029940119760479\n",
      "simulated_annealing: 1401 - duration: 1.5924410820007324, tr_acc: 0.43322475570032576, test_acc: 0.4675324675324675, f1: 0.5060240963855421\n",
      "simulated_annealing: 1501 - duration: 1.727193832397461, tr_acc: 0.43159609120521175, test_acc: 0.4675324675324675, f1: 0.5060240963855421\n",
      "simulated_annealing: 1601 - duration: 1.844801902770996, tr_acc: 0.43973941368078173, test_acc: 0.474025974025974, f1: 0.509090909090909\n",
      "simulated_annealing: 1701 - duration: 1.9261658191680908, tr_acc: 0.4527687296416938, test_acc: 0.4675324675324675, f1: 0.4938271604938272\n",
      "simulated_annealing: 1801 - duration: 2.0351037979125977, tr_acc: 0.4560260586319218, test_acc: 0.461038961038961, f1: 0.484472049689441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated_annealing: 1901 - duration: 2.164673089981079, tr_acc: 0.4576547231270358, test_acc: 0.461038961038961, f1: 0.47798742138364775\n",
      "simulated_annealing: 2001 - duration: 2.2652769088745117, tr_acc: 0.46905537459283386, test_acc: 0.474025974025974, f1: 0.4840764331210191\n",
      "simulated_annealing: 2101 - duration: 2.3690850734710693, tr_acc: 0.49185667752442996, test_acc: 0.5064935064935064, f1: 0.49333333333333335\n",
      "simulated_annealing: 2201 - duration: 2.5027239322662354, tr_acc: 0.504885993485342, test_acc: 0.5064935064935064, f1: 0.49333333333333335\n",
      "simulated_annealing: 2301 - duration: 2.6028919219970703, tr_acc: 0.50814332247557, test_acc: 0.5, f1: 0.4832214765100671\n",
      "simulated_annealing: 2401 - duration: 2.7242398262023926, tr_acc: 0.509771986970684, test_acc: 0.5, f1: 0.4832214765100671\n",
      "simulated_annealing: 2501 - duration: 2.8277578353881836, tr_acc: 0.509771986970684, test_acc: 0.5, f1: 0.47619047619047616\n",
      "simulated_annealing: 2601 - duration: 2.9458210468292236, tr_acc: 0.5162866449511401, test_acc: 0.512987012987013, f1: 0.48979591836734687\n",
      "simulated_annealing: 2701 - duration: 3.0789811611175537, tr_acc: 0.5162866449511401, test_acc: 0.5064935064935064, f1: 0.4794520547945205\n",
      "simulated_annealing: 2801 - duration: 3.1913559436798096, tr_acc: 0.5195439739413681, test_acc: 0.5064935064935064, f1: 0.4794520547945205\n",
      "simulated_annealing: 2901 - duration: 3.296957015991211, tr_acc: 0.5276872964169381, test_acc: 0.512987012987013, f1: 0.4827586206896552\n",
      "simulated_annealing: 3001 - duration: 3.476716995239258, tr_acc: 0.5358306188925082, test_acc: 0.5194805194805194, f1: 0.49315068493150693\n",
      "simulated_annealing: 3101 - duration: 3.5007131099700928, tr_acc: 0.5472312703583062, test_acc: 0.538961038961039, f1: 0.5034965034965035\n",
      "simulated_annealing: 3201 - duration: 3.6050350666046143, tr_acc: 0.5488599348534202, test_acc: 0.525974025974026, f1: 0.48951048951048953\n",
      "simulated_annealing: 3301 - duration: 3.829069137573242, tr_acc: 0.5472312703583062, test_acc: 0.5454545454545454, f1: 0.5070422535211268\n",
      "simulated_annealing: 3401 - duration: 3.913784980773926, tr_acc: 0.5472312703583062, test_acc: 0.5584415584415584, f1: 0.5142857142857142\n",
      "simulated_annealing: 3501 - duration: 3.920336961746216, tr_acc: 0.5586319218241043, test_acc: 0.551948051948052, f1: 0.5035971223021583\n",
      "simulated_annealing: 3601 - duration: 4.068490028381348, tr_acc: 0.5553745928338762, test_acc: 0.5454545454545454, f1: 0.4927536231884058\n",
      "simulated_annealing: 3701 - duration: 4.136572360992432, tr_acc: 0.5570032573289903, test_acc: 0.551948051948052, f1: 0.5035971223021583\n",
      "simulated_annealing: 3801 - duration: 4.3193519115448, tr_acc: 0.5602605863192183, test_acc: 0.5454545454545454, f1: 0.4927536231884058\n",
      "simulated_annealing: 3901 - duration: 4.412644863128662, tr_acc: 0.5635179153094463, test_acc: 0.5584415584415584, f1: 0.5072463768115941\n",
      "simulated_annealing: 4001 - duration: 4.554853200912476, tr_acc: 0.5765472312703583, test_acc: 0.5714285714285714, f1: 0.5074626865671642\n",
      "simulated_annealing: 4101 - duration: 4.635341167449951, tr_acc: 0.5798045602605864, test_acc: 0.577922077922078, f1: 0.5112781954887218\n",
      "simulated_annealing: 4201 - duration: 4.668885946273804, tr_acc: 0.5798045602605864, test_acc: 0.577922077922078, f1: 0.5185185185185185\n",
      "simulated_annealing: 4301 - duration: 4.9566028118133545, tr_acc: 0.5846905537459284, test_acc: 0.5909090909090909, f1: 0.5333333333333333\n",
      "simulated_annealing: 4401 - duration: 4.991259813308716, tr_acc: 0.5863192182410424, test_acc: 0.5714285714285714, f1: 0.5\n",
      "simulated_annealing: 4501 - duration: 5.107683181762695, tr_acc: 0.5879478827361564, test_acc: 0.5844155844155844, f1: 0.5223880597014925\n",
      "simulated_annealing: 4601 - duration: 5.1920270919799805, tr_acc: 0.5912052117263844, test_acc: 0.5844155844155844, f1: 0.5223880597014925\n",
      "simulated_annealing: 4701 - duration: 5.321293115615845, tr_acc: 0.5944625407166124, test_acc: 0.5974025974025974, f1: 0.5303030303030303\n",
      "simulated_annealing: 4801 - duration: 5.4130940437316895, tr_acc: 0.6009771986970684, test_acc: 0.6103896103896104, f1: 0.5454545454545455\n",
      "simulated_annealing: 4901 - duration: 5.56407904624939, tr_acc: 0.6074918566775245, test_acc: 0.5974025974025974, f1: 0.523076923076923\n",
      "simulated_annealing: 5001 - duration: 5.648737907409668, tr_acc: 0.6091205211726385, test_acc: 0.6038961038961039, f1: 0.5271317829457364\n",
      "genetic_alg: 1 - duration: 0.22910404205322266, tr_acc: 0.6921824104234527, test_acc: 0.7272727272727273, f1: 0.6557377049180328\n",
      "genetic_alg: 101 - duration: 12.039672136306763, tr_acc: 0.7899022801302932, test_acc: 0.6948051948051948, f1: 0.5765765765765765\n",
      "genetic_alg: 201 - duration: 24.07123899459839, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 301 - duration: 28.70036292076111, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 401 - duration: 29.04696798324585, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 501 - duration: 28.741604804992676, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 601 - duration: 29.004985094070435, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 701 - duration: 29.180508136749268, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 801 - duration: 28.772468090057373, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 901 - duration: 28.924072980880737, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1001 - duration: 28.202906847000122, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1101 - duration: 28.294586181640625, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1201 - duration: 27.88554883003235, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1301 - duration: 27.730474948883057, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1401 - duration: 27.595265865325928, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1501 - duration: 27.403970956802368, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1601 - duration: 27.138754844665527, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1701 - duration: 27.36083722114563, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1801 - duration: 27.27190923690796, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1901 - duration: 27.55651092529297, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2001 - duration: 27.52101469039917, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2101 - duration: 28.486634016036987, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2201 - duration: 27.954432010650635, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2301 - duration: 27.6995849609375, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2401 - duration: 27.80815839767456, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2501 - duration: 27.691706895828247, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2601 - duration: 27.482600212097168, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2701 - duration: 27.557560920715332, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2801 - duration: 27.7165310382843, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 2901 - duration: 27.67165493965149, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genetic_alg: 3001 - duration: 27.960888147354126, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3101 - duration: 28.129078149795532, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3201 - duration: 28.227720022201538, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3301 - duration: 28.550740957260132, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3401 - duration: 28.695610284805298, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3501 - duration: 28.244951009750366, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3601 - duration: 28.084779977798462, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3701 - duration: 28.60203528404236, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3801 - duration: 27.85966396331787, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 3901 - duration: 27.4544358253479, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4001 - duration: 27.958115100860596, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4101 - duration: 28.031845092773438, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4201 - duration: 28.172932863235474, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4301 - duration: 28.730472087860107, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4401 - duration: 28.972109079360962, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4501 - duration: 29.2048020362854, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4601 - duration: 29.130130290985107, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4701 - duration: 28.91621470451355, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4801 - duration: 28.96181607246399, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 4901 - duration: 29.121269941329956, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 5001 - duration: 28.899654865264893, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n"
     ]
    }
   ],
   "source": [
    "#Backprob\n",
    "\n",
    "selected_algorithm=['gradient_descent', \"random_hill_climb\", \"simulated_annealing\", \"genetic_alg\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for algo in selected_algorithm:\n",
    "    for step in range(1, 5002, 100):\n",
    "        start_time = time.time()\n",
    "        clf = mlrose_hiive.NeuralNetwork(hidden_nodes=[10], algorithm=algo,\n",
    "                                                  early_stopping=True, max_iters=step, random_state=seed,\n",
    "                                                  curve=True, max_attempts=100, learning_rate=0.01, activation=\"tanh\"\n",
    "                                             )\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        y_tr_pred = clf.predict(X_train)\n",
    "        tr_acc = accuracy_score(y_train, y_tr_pred)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        f1 = f1_score(y_test, y_test_pred)    \n",
    "\n",
    "        results.append([step, algo, duration, tr_acc, test_acc, f1])\n",
    "        print(f\"{algo}: {step} - duration: {duration}, tr_acc: {tr_acc}, test_acc: {test_acc}, f1: {f1}\")\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"steps\", \"algo\", \"duration\", \"train_acc\", \"test_accuracy\", \"f1_score\"])\n",
    "df.to_csv(\"optimization_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>algo</th>\n",
       "      <th>duration</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.713355</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.135270</td>\n",
       "      <td>0.806189</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.264292</td>\n",
       "      <td>0.811075</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.653465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.383328</td>\n",
       "      <td>0.820847</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.594059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.544135</td>\n",
       "      <td>0.833876</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   steps              algo  duration  train_acc  test_accuracy  f1_score\n",
       "0      1  gradient_descent  0.004375   0.713355       0.727273  0.500000\n",
       "1    101  gradient_descent  0.135270   0.806189       0.740260  0.622642\n",
       "2    201  gradient_descent  0.264292   0.811075       0.772727  0.653465\n",
       "3    301  gradient_descent  0.383328   0.820847       0.733766  0.594059\n",
       "4    401  gradient_descent  0.544135   0.833876       0.772727  0.646465"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_algo(algo_name, color=\"g\", save_abb=\"test\"):\n",
    "    print(f\"compare algorith with {algo_name}\")\n",
    "    grad_descent = df[df.algo == \"gradient_descent\"]\n",
    "    iters = grad_descent[\"steps\"]\n",
    "    grad_f1 = grad_descent[\"f1_score\"]\n",
    "    grad_time = grad_descent[\"duration\"]\n",
    "    \n",
    "    new_algo = df[df.algo == algo_name]\n",
    "    new_algo_f1 = new_algo[\"f1_score\"]\n",
    "    new_algo_time = new_algo[\"duration\"]\n",
    "\n",
    "    plt.plot(iters, grad_f1, label=\"backpropagation\", color=\"b\")\n",
    "    plt.plot(iters, new_algo_f1, label=algo_name, color=color)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.savefig(f\"{save_abb}_f1.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(iters, grad_time, label=\"backpropagation\", color=\"b\")\n",
    "    plt.plot(iters, new_algo_time, label=algo_name, color=color)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Time (ms)\")\n",
    "    plt.savefig(f\"{save_abb}_duration.png\")    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare algorith with random_hill_climb\n",
      "compare algorith with simulated_annealing\n",
      "compare algorith with genetic_alg\n"
     ]
    }
   ],
   "source": [
    "plotting_algo(selected_algorithm[1], color=\"g\", save_abb=\"rhc\")\n",
    "plotting_algo(selected_algorithm[2], color=\"r\", save_abb=\"sa\")\n",
    "plotting_algo(selected_algorithm[3], color=\"y\", save_abb=\"ghc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradient_descent', 'random_hill_climb', 'simulated_annealing', 'genetic_alg']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_algo_total(algo_list):\n",
    "    grad_descent = df[df.algo == \"gradient_descent\"]\n",
    "    iters = grad_descent[\"steps\"]\n",
    "    grad_f1 = grad_descent[\"f1_score\"]\n",
    "    grad_time = grad_descent[\"duration\"]\n",
    "\n",
    "    rhc = df[df.algo == algo_list[1]]\n",
    "    rhc_f1 = rhc[\"f1_score\"]\n",
    "    rhc_time = rhc[\"duration\"]\n",
    "    \n",
    "    sa = df[df.algo == algo_list[2]]\n",
    "    sa_f1 = sa[\"f1_score\"]\n",
    "    sa_time = sa[\"duration\"]\n",
    "    \n",
    "    ga = df[df.algo == algo_list[3]]\n",
    "    ga_f1 = ga[\"f1_score\"]\n",
    "    ga_time = ga[\"duration\"]\n",
    "\n",
    "    plt.plot(iters, grad_f1, label=\"backpropagation\", color=\"b\")\n",
    "    plt.plot(iters, rhc_f1, label=algo_list[1], color=\"g\")\n",
    "    plt.plot(iters, sa_f1, label=algo_list[2], color=\"r\")\n",
    "    plt.plot(iters, ga_f1, label=algo_list[3], color=\"y\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.savefig(f\"total_f1.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(iters, grad_time, label=\"backpropagation\", color=\"C1\")\n",
    "    plt.plot(iters, rhc_time, label=algo_list[1], color=\"g\")\n",
    "    plt.plot(iters, sa_time, label=algo_list[2], color=\"r\")\n",
    "    plt.plot(iters, ga_time, label=algo_list[3], color=\"y\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Time (ms)\")\n",
    "    plt.savefig(f\"total_duration.png\")    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_algo_total(selected_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
