{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "import mlrose_hiive\n",
    "\n",
    "# Models\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from utils import learning_curve_plotter, model_param_curve, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base param\n",
    "seed = 712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "diabet_path = \"./data/diabetes.csv\"\n",
    "df_diabet = pd.read_csv(diabet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diabet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0          500\n",
      "1          268\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize target value\n",
    "\n",
    "target_cnt = df_diabet[[\"Outcome\"]].value_counts()\n",
    "print(target_cnt)\n",
    "\n",
    "target_cnt.plot(kind='barh', title=\"Target Value Count\")\n",
    "plt.xlabel(\"diabet\")\n",
    "plt.ylabel(\"examples\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0          0.651042\n",
       "1          0.348958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cnt / len(df_diabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Outcome'\n",
    "features = [ 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "train_df, test_df = train_test_split(df_diabet, test_size=0.2, random_state=712)\n",
    "X_train_origin, y_train = train_df[features], train_df[target]\n",
    "X_test_origin, y_test = test_df[features], test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalize\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_origin)\n",
    "\n",
    "X_train = sc.transform(X_train_origin)\n",
    "X_test = sc.transform(X_test_origin)\n",
    "\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     print(f\"Range after normalize feature {i}'s {min(X_train_origin[:, i])} ~ {max(X_train_origin[:, i])} to {min(X_train[:, i])} ~ {max(X_train[:, i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent: 1 - duration: 0.0054399967193603516, tr_acc: 0.7133550488599348, test_acc: 0.7272727272727273, f1: 0.5\n",
      "gradient_descent: 51 - duration: 0.06749987602233887, tr_acc: 0.7931596091205212, test_acc: 0.7597402597402597, f1: 0.6262626262626262\n",
      "gradient_descent: 101 - duration: 0.12499308586120605, tr_acc: 0.8061889250814332, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 151 - duration: 0.18862104415893555, tr_acc: 0.8045602605863192, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 201 - duration: 0.2511632442474365, tr_acc: 0.8110749185667753, test_acc: 0.7727272727272727, f1: 0.6534653465346535\n",
      "gradient_descent: 251 - duration: 0.3104078769683838, tr_acc: 0.8224755700325733, test_acc: 0.7272727272727273, f1: 0.5961538461538461\n",
      "gradient_descent: 301 - duration: 0.38069725036621094, tr_acc: 0.8208469055374593, test_acc: 0.7337662337662337, f1: 0.594059405940594\n",
      "gradient_descent: 351 - duration: 0.43505001068115234, tr_acc: 0.8175895765472313, test_acc: 0.7207792207792207, f1: 0.6055045871559633\n",
      "gradient_descent: 401 - duration: 0.5024991035461426, tr_acc: 0.8338762214983714, test_acc: 0.7727272727272727, f1: 0.6464646464646465\n",
      "gradient_descent: 451 - duration: 0.566896915435791, tr_acc: 0.8289902280130294, test_acc: 0.7662337662337663, f1: 0.6470588235294117\n",
      "gradient_descent: 501 - duration: 0.612889289855957, tr_acc: 0.8289902280130294, test_acc: 0.7532467532467533, f1: 0.6274509803921569\n",
      "gradient_descent: 551 - duration: 0.69240403175354, tr_acc: 0.8387622149837134, test_acc: 0.7597402597402597, f1: 0.6407766990291263\n",
      "gradient_descent: 601 - duration: 0.7657291889190674, tr_acc: 0.8306188925081434, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 651 - duration: 0.8076138496398926, tr_acc: 0.8387622149837134, test_acc: 0.7532467532467533, f1: 0.6481481481481481\n",
      "gradient_descent: 701 - duration: 0.8684999942779541, tr_acc: 0.8517915309446255, test_acc: 0.7402597402597403, f1: 0.607843137254902\n",
      "gradient_descent: 751 - duration: 0.9902541637420654, tr_acc: 0.8517915309446255, test_acc: 0.7337662337662337, f1: 0.6095238095238096\n",
      "gradient_descent: 801 - duration: 1.029968023300171, tr_acc: 0.8485342019543974, test_acc: 0.7402597402597403, f1: 0.6226415094339622\n",
      "gradient_descent: 851 - duration: 1.0971298217773438, tr_acc: 0.8501628664495114, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 901 - duration: 1.1055750846862793, tr_acc: 0.8485342019543974, test_acc: 0.7402597402597403, f1: 0.6296296296296295\n",
      "gradient_descent: 951 - duration: 1.1852450370788574, tr_acc: 0.8501628664495114, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1001 - duration: 1.280513048171997, tr_acc: 0.8534201954397395, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1051 - duration: 1.3523690700531006, tr_acc: 0.8534201954397395, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 1101 - duration: 1.408357858657837, tr_acc: 0.8599348534201955, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 1151 - duration: 1.4915828704833984, tr_acc: 0.8648208469055375, test_acc: 0.7402597402597403, f1: 0.6296296296296295\n",
      "gradient_descent: 1201 - duration: 1.5555908679962158, tr_acc: 0.8648208469055375, test_acc: 0.7337662337662337, f1: 0.6238532110091743\n",
      "gradient_descent: 1251 - duration: 1.5987591743469238, tr_acc: 0.8680781758957655, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 1301 - duration: 1.6593668460845947, tr_acc: 0.8713355048859935, test_acc: 0.7337662337662337, f1: 0.6238532110091743\n",
      "gradient_descent: 1351 - duration: 1.725466012954712, tr_acc: 0.8680781758957655, test_acc: 0.7272727272727273, f1: 0.6181818181818182\n",
      "gradient_descent: 1401 - duration: 1.7964129447937012, tr_acc: 0.8648208469055375, test_acc: 0.7337662337662337, f1: 0.6238532110091743\n",
      "gradient_descent: 1451 - duration: 1.8565399646759033, tr_acc: 0.8648208469055375, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 1501 - duration: 1.934359073638916, tr_acc: 0.8648208469055375, test_acc: 0.7402597402597403, f1: 0.6363636363636364\n",
      "gradient_descent: 1551 - duration: 1.9801790714263916, tr_acc: 0.8664495114006515, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1601 - duration: 1.9940710067749023, tr_acc: 0.8664495114006515, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1651 - duration: 1.9901680946350098, tr_acc: 0.8680781758957655, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1701 - duration: 2.116797924041748, tr_acc: 0.8648208469055375, test_acc: 0.7467532467532467, f1: 0.6422018348623854\n",
      "gradient_descent: 1751 - duration: 2.2256360054016113, tr_acc: 0.8664495114006515, test_acc: 0.7402597402597403, f1: 0.6296296296296295\n",
      "gradient_descent: 1801 - duration: 2.2546801567077637, tr_acc: 0.8680781758957655, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 1851 - duration: 2.3509271144866943, tr_acc: 0.8680781758957655, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 1901 - duration: 2.4570231437683105, tr_acc: 0.8680781758957655, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "gradient_descent: 1951 - duration: 2.5139381885528564, tr_acc: 0.8680781758957655, test_acc: 0.7337662337662337, f1: 0.6168224299065421\n",
      "random_hill_climb: 1 - duration: 0.002109050750732422, tr_acc: 0.3925081433224756, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "random_hill_climb: 51 - duration: 0.05005383491516113, tr_acc: 0.3941368078175896, test_acc: 0.43506493506493504, f1: 0.5028571428571429\n",
      "random_hill_climb: 101 - duration: 0.09786081314086914, tr_acc: 0.4006514657980456, test_acc: 0.44155844155844154, f1: 0.5057471264367817\n",
      "random_hill_climb: 151 - duration: 0.1450948715209961, tr_acc: 0.40390879478827363, test_acc: 0.44155844155844154, f1: 0.5057471264367817\n",
      "random_hill_climb: 201 - duration: 0.18128681182861328, tr_acc: 0.41205211726384366, test_acc: 0.44155844155844154, f1: 0.5057471264367817\n",
      "random_hill_climb: 251 - duration: 0.22684788703918457, tr_acc: 0.41368078175895767, test_acc: 0.44805194805194803, f1: 0.5086705202312138\n",
      "random_hill_climb: 301 - duration: 0.2793009281158447, tr_acc: 0.4153094462540717, test_acc: 0.44805194805194803, f1: 0.5086705202312138\n",
      "random_hill_climb: 351 - duration: 0.32285594940185547, tr_acc: 0.4153094462540717, test_acc: 0.44155844155844154, f1: 0.5\n",
      "random_hill_climb: 401 - duration: 0.3665432929992676, tr_acc: 0.4169381107491857, test_acc: 0.45454545454545453, f1: 0.5058823529411764\n",
      "random_hill_climb: 451 - duration: 0.40961599349975586, tr_acc: 0.4218241042345277, test_acc: 0.4675324675324675, f1: 0.511904761904762\n",
      "random_hill_climb: 501 - duration: 0.443497896194458, tr_acc: 0.42671009771986973, test_acc: 0.474025974025974, f1: 0.5149700598802396\n",
      "random_hill_climb: 551 - duration: 0.48697495460510254, tr_acc: 0.4381107491856677, test_acc: 0.4805194805194805, f1: 0.5180722891566265\n",
      "random_hill_climb: 601 - duration: 0.531480073928833, tr_acc: 0.44136807817589574, test_acc: 0.4805194805194805, f1: 0.5180722891566265\n",
      "random_hill_climb: 651 - duration: 0.581373929977417, tr_acc: 0.44299674267100975, test_acc: 0.4805194805194805, f1: 0.5180722891566265\n",
      "random_hill_climb: 701 - duration: 0.6257870197296143, tr_acc: 0.44462540716612375, test_acc: 0.474025974025974, f1: 0.509090909090909\n",
      "random_hill_climb: 751 - duration: 0.7048509120941162, tr_acc: 0.44625407166123776, test_acc: 0.474025974025974, f1: 0.509090909090909\n",
      "random_hill_climb: 801 - duration: 0.7153050899505615, tr_acc: 0.4495114006514658, test_acc: 0.4675324675324675, f1: 0.5\n",
      "random_hill_climb: 851 - duration: 0.7401390075683594, tr_acc: 0.4723127035830619, test_acc: 0.4805194805194805, f1: 0.5061728395061729\n",
      "random_hill_climb: 901 - duration: 0.7744021415710449, tr_acc: 0.4739413680781759, test_acc: 0.4935064935064935, f1: 0.5125000000000001\n",
      "random_hill_climb: 951 - duration: 0.8315908908843994, tr_acc: 0.48534201954397393, test_acc: 0.5064935064935064, f1: 0.5189873417721519\n",
      "random_hill_climb: 1001 - duration: 0.8772149085998535, tr_acc: 0.49022801302931596, test_acc: 0.5064935064935064, f1: 0.5189873417721519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_hill_climb: 1051 - duration: 0.9236726760864258, tr_acc: 0.495114006514658, test_acc: 0.5194805194805194, f1: 0.5256410256410257\n",
      "random_hill_climb: 1101 - duration: 0.9879541397094727, tr_acc: 0.501628664495114, test_acc: 0.538961038961039, f1: 0.5359477124183006\n",
      "random_hill_climb: 1151 - duration: 1.036984920501709, tr_acc: 0.511400651465798, test_acc: 0.5454545454545454, f1: 0.5394736842105263\n",
      "random_hill_climb: 1201 - duration: 1.1011271476745605, tr_acc: 0.5162866449511401, test_acc: 0.564935064935065, f1: 0.5503355704697986\n",
      "random_hill_climb: 1251 - duration: 1.1458549499511719, tr_acc: 0.5244299674267101, test_acc: 0.577922077922078, f1: 0.5578231292517007\n",
      "random_hill_climb: 1301 - duration: 1.1700432300567627, tr_acc: 0.5309446254071661, test_acc: 0.577922077922078, f1: 0.5578231292517007\n",
      "random_hill_climb: 1351 - duration: 1.2049338817596436, tr_acc: 0.5342019543973942, test_acc: 0.5844155844155844, f1: 0.5616438356164384\n",
      "random_hill_climb: 1401 - duration: 1.23313307762146, tr_acc: 0.5488599348534202, test_acc: 0.5909090909090909, f1: 0.5655172413793104\n",
      "random_hill_climb: 1451 - duration: 1.3012909889221191, tr_acc: 0.5586319218241043, test_acc: 0.5909090909090909, f1: 0.5594405594405594\n",
      "random_hill_climb: 1501 - duration: 1.361914873123169, tr_acc: 0.5684039087947883, test_acc: 0.5974025974025974, f1: 0.5633802816901408\n",
      "random_hill_climb: 1551 - duration: 1.3714511394500732, tr_acc: 0.5765472312703583, test_acc: 0.6168831168831169, f1: 0.5755395683453237\n",
      "random_hill_climb: 1601 - duration: 1.437518835067749, tr_acc: 0.5846905537459284, test_acc: 0.6233766233766234, f1: 0.5797101449275363\n",
      "random_hill_climb: 1651 - duration: 1.4973137378692627, tr_acc: 0.5928338762214984, test_acc: 0.6233766233766234, f1: 0.5735294117647058\n",
      "random_hill_climb: 1701 - duration: 1.5213050842285156, tr_acc: 0.6074918566775245, test_acc: 0.6363636363636364, f1: 0.5882352941176471\n",
      "random_hill_climb: 1751 - duration: 1.5672242641448975, tr_acc: 0.6123778501628665, test_acc: 0.6428571428571429, f1: 0.5925925925925926\n",
      "random_hill_climb: 1801 - duration: 1.617569923400879, tr_acc: 0.6205211726384365, test_acc: 0.6428571428571429, f1: 0.5925925925925926\n",
      "random_hill_climb: 1851 - duration: 1.7013609409332275, tr_acc: 0.6221498371335505, test_acc: 0.6623376623376623, f1: 0.6060606060606061\n",
      "random_hill_climb: 1901 - duration: 1.690744161605835, tr_acc: 0.6254071661237784, test_acc: 0.6558441558441559, f1: 0.5954198473282444\n",
      "random_hill_climb: 1951 - duration: 1.7699151039123535, tr_acc: 0.6384364820846905, test_acc: 0.6558441558441559, f1: 0.5891472868217055\n",
      "simulated_annealing: 1 - duration: 0.0022869110107421875, tr_acc: 0.3925081433224756, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "simulated_annealing: 51 - duration: 0.06118178367614746, tr_acc: 0.39087947882736157, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "simulated_annealing: 101 - duration: 0.12226510047912598, tr_acc: 0.3925081433224756, test_acc: 0.43506493506493504, f1: 0.5028571428571429\n",
      "simulated_annealing: 151 - duration: 0.18396711349487305, tr_acc: 0.3941368078175896, test_acc: 0.42857142857142855, f1: 0.48837209302325585\n",
      "simulated_annealing: 201 - duration: 0.2293071746826172, tr_acc: 0.3925081433224756, test_acc: 0.4025974025974026, f1: 0.47727272727272724\n",
      "simulated_annealing: 251 - duration: 0.28560900688171387, tr_acc: 0.3925081433224756, test_acc: 0.4090909090909091, f1: 0.48\n",
      "simulated_annealing: 301 - duration: 0.348311185836792, tr_acc: 0.3973941368078176, test_acc: 0.4155844155844156, f1: 0.4827586206896552\n",
      "simulated_annealing: 351 - duration: 0.4120030403137207, tr_acc: 0.3957654723127036, test_acc: 0.4090909090909091, f1: 0.48587570621468923\n",
      "simulated_annealing: 401 - duration: 0.46702075004577637, tr_acc: 0.3941368078175896, test_acc: 0.4025974025974026, f1: 0.47727272727272724\n",
      "simulated_annealing: 451 - duration: 0.5142261981964111, tr_acc: 0.3941368078175896, test_acc: 0.4025974025974026, f1: 0.48314606741573035\n",
      "simulated_annealing: 501 - duration: 0.574822187423706, tr_acc: 0.3941368078175896, test_acc: 0.4090909090909091, f1: 0.48587570621468923\n",
      "simulated_annealing: 551 - duration: 0.6287453174591064, tr_acc: 0.3957654723127036, test_acc: 0.4025974025974026, f1: 0.48314606741573035\n",
      "simulated_annealing: 601 - duration: 0.7024199962615967, tr_acc: 0.3925081433224756, test_acc: 0.4025974025974026, f1: 0.48314606741573035\n",
      "simulated_annealing: 651 - duration: 0.7278211116790771, tr_acc: 0.3941368078175896, test_acc: 0.4155844155844156, f1: 0.48863636363636365\n",
      "simulated_annealing: 701 - duration: 0.798166036605835, tr_acc: 0.39087947882736157, test_acc: 0.42207792207792205, f1: 0.49142857142857144\n",
      "simulated_annealing: 751 - duration: 0.8704261779785156, tr_acc: 0.3941368078175896, test_acc: 0.42857142857142855, f1: 0.49425287356321834\n",
      "simulated_annealing: 801 - duration: 0.9230499267578125, tr_acc: 0.3973941368078176, test_acc: 0.42857142857142855, f1: 0.49425287356321834\n",
      "simulated_annealing: 851 - duration: 0.9523861408233643, tr_acc: 0.40390879478827363, test_acc: 0.42857142857142855, f1: 0.49425287356321834\n",
      "simulated_annealing: 901 - duration: 0.9961340427398682, tr_acc: 0.40879478827361565, test_acc: 0.42857142857142855, f1: 0.49425287356321834\n",
      "simulated_annealing: 951 - duration: 1.0452730655670166, tr_acc: 0.41042345276872966, test_acc: 0.42857142857142855, f1: 0.48837209302325585\n",
      "simulated_annealing: 1001 - duration: 1.1250622272491455, tr_acc: 0.41368078175895767, test_acc: 0.43506493506493504, f1: 0.49710982658959535\n",
      "simulated_annealing: 1051 - duration: 1.1621170043945312, tr_acc: 0.4153094462540717, test_acc: 0.42857142857142855, f1: 0.48837209302325585\n",
      "simulated_annealing: 1101 - duration: 1.246434211730957, tr_acc: 0.4201954397394137, test_acc: 0.43506493506493504, f1: 0.4912280701754386\n",
      "simulated_annealing: 1151 - duration: 1.2809770107269287, tr_acc: 0.4234527687296417, test_acc: 0.44805194805194803, f1: 0.49704142011834324\n",
      "simulated_annealing: 1201 - duration: 1.3545773029327393, tr_acc: 0.4234527687296417, test_acc: 0.461038961038961, f1: 0.5029940119760479\n",
      "simulated_annealing: 1251 - duration: 1.4407291412353516, tr_acc: 0.4218241042345277, test_acc: 0.461038961038961, f1: 0.5029940119760479\n",
      "simulated_annealing: 1301 - duration: 1.4869630336761475, tr_acc: 0.42996742671009774, test_acc: 0.461038961038961, f1: 0.5029940119760479\n",
      "simulated_annealing: 1351 - duration: 1.5424180030822754, tr_acc: 0.42996742671009774, test_acc: 0.4675324675324675, f1: 0.5060240963855421\n",
      "simulated_annealing: 1401 - duration: 1.6007821559906006, tr_acc: 0.43322475570032576, test_acc: 0.4675324675324675, f1: 0.5060240963855421\n",
      "simulated_annealing: 1451 - duration: 1.654745101928711, tr_acc: 0.43322475570032576, test_acc: 0.461038961038961, f1: 0.49696969696969695\n",
      "simulated_annealing: 1501 - duration: 1.6685187816619873, tr_acc: 0.43159609120521175, test_acc: 0.4675324675324675, f1: 0.5060240963855421\n",
      "simulated_annealing: 1551 - duration: 1.7386538982391357, tr_acc: 0.44136807817589574, test_acc: 0.4675324675324675, f1: 0.5\n",
      "simulated_annealing: 1601 - duration: 1.7641618251800537, tr_acc: 0.43973941368078173, test_acc: 0.474025974025974, f1: 0.509090909090909\n",
      "simulated_annealing: 1651 - duration: 1.827470064163208, tr_acc: 0.44625407166123776, test_acc: 0.4675324675324675, f1: 0.5\n",
      "simulated_annealing: 1701 - duration: 1.895082950592041, tr_acc: 0.4527687296416938, test_acc: 0.4675324675324675, f1: 0.4938271604938272\n",
      "simulated_annealing: 1751 - duration: 1.9755778312683105, tr_acc: 0.4560260586319218, test_acc: 0.4675324675324675, f1: 0.4938271604938272\n",
      "simulated_annealing: 1801 - duration: 1.9986140727996826, tr_acc: 0.4560260586319218, test_acc: 0.461038961038961, f1: 0.484472049689441\n",
      "simulated_annealing: 1851 - duration: 2.082043170928955, tr_acc: 0.4560260586319218, test_acc: 0.45454545454545453, f1: 0.47500000000000003\n",
      "simulated_annealing: 1901 - duration: 2.1643688678741455, tr_acc: 0.4576547231270358, test_acc: 0.461038961038961, f1: 0.47798742138364775\n",
      "simulated_annealing: 1951 - duration: 2.2545742988586426, tr_acc: 0.46254071661237783, test_acc: 0.4675324675324675, f1: 0.48101265822784806\n",
      "genetic_alg: 1 - duration: 0.22806406021118164, tr_acc: 0.6921824104234527, test_acc: 0.7272727272727273, f1: 0.6557377049180328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genetic_alg: 51 - duration: 5.980211973190308, tr_acc: 0.7850162866449512, test_acc: 0.7402597402597403, f1: 0.607843137254902\n",
      "genetic_alg: 101 - duration: 12.048986911773682, tr_acc: 0.7899022801302932, test_acc: 0.6948051948051948, f1: 0.5765765765765765\n",
      "genetic_alg: 151 - duration: 18.25527596473694, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 201 - duration: 23.38088893890381, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 251 - duration: 27.622260093688965, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 301 - duration: 27.331212043762207, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 351 - duration: 27.43980383872986, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 401 - duration: 27.08780002593994, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 451 - duration: 27.288304090499878, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 501 - duration: 27.046307802200317, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 551 - duration: 27.135704278945923, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 601 - duration: 27.05388593673706, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 651 - duration: 26.925116300582886, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 701 - duration: 26.99761986732483, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 751 - duration: 27.053178071975708, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 801 - duration: 26.96859884262085, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 851 - duration: 27.023371934890747, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 901 - duration: 27.0214900970459, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 951 - duration: 27.662726163864136, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1001 - duration: 27.589653968811035, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1051 - duration: 27.140939950942993, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1101 - duration: 27.155112743377686, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1151 - duration: 27.07404899597168, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1201 - duration: 27.88052201271057, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1251 - duration: 27.82183313369751, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1301 - duration: 27.863065004348755, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1351 - duration: 27.526589155197144, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1401 - duration: 27.67673969268799, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1451 - duration: 27.300837993621826, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1501 - duration: 27.052928924560547, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1551 - duration: 26.93260908126831, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1601 - duration: 26.960169076919556, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1651 - duration: 27.32852816581726, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1701 - duration: 27.06324028968811, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1751 - duration: 26.977763175964355, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1801 - duration: 27.096981048583984, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1851 - duration: 27.089269161224365, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1901 - duration: 27.05690312385559, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n",
      "genetic_alg: 1951 - duration: 27.544071197509766, tr_acc: 0.7980456026058632, test_acc: 0.7467532467532467, f1: 0.6213592233009709\n"
     ]
    }
   ],
   "source": [
    "#Backprob\n",
    "\n",
    "selected_algorithm=['gradient_descent', \"random_hill_climb\", \"simulated_annealing\", \"genetic_alg\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for algo in selected_algorithm:\n",
    "    for step in range(1, 2001, 50):\n",
    "        start_time = time.time()\n",
    "        clf = mlrose_hiive.NeuralNetwork(hidden_nodes=[10], algorithm=algo,\n",
    "                                                  early_stopping=True, max_iters=step, random_state=seed,\n",
    "                                                  curve=True, max_attempts=100, learning_rate=0.01, activation=\"tanh\"\n",
    "                                             )\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        y_tr_pred = clf.predict(X_train)\n",
    "        tr_acc = accuracy_score(y_train, y_tr_pred)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        f1 = f1_score(y_test, y_test_pred)    \n",
    "\n",
    "        results.append([step, algo, duration, tr_acc, test_acc, f1])\n",
    "        print(f\"{algo}: {step} - duration: {duration}, tr_acc: {tr_acc}, test_acc: {test_acc}, f1: {f1}\")\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"steps\", \"algo\", \"duration\", \"train_acc\", \"test_accuracy\", \"f1_score\"])\n",
    "df.to_csv(\"optimization_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>algo</th>\n",
       "      <th>duration</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.713355</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.793160</td>\n",
       "      <td>0.759740</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.806189</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.188621</td>\n",
       "      <td>0.804560</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>0.251163</td>\n",
       "      <td>0.811075</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.653465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   steps              algo  duration  train_acc  test_accuracy  f1_score\n",
       "0      1  gradient_descent  0.005440   0.713355       0.727273  0.500000\n",
       "1     51  gradient_descent  0.067500   0.793160       0.759740  0.626263\n",
       "2    101  gradient_descent  0.124993   0.806189       0.740260  0.622642\n",
       "3    151  gradient_descent  0.188621   0.804560       0.740260  0.622642\n",
       "4    201  gradient_descent  0.251163   0.811075       0.772727  0.653465"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_algo(algo_name, color=\"g\", save_abb=\"test\"):\n",
    "    print(f\"compare algorith with {algo_name}\")\n",
    "    grad_descent = df[df.algo == \"gradient_descent\"]\n",
    "    iters = grad_descent[\"steps\"]\n",
    "    grad_f1 = grad_descent[\"f1_score\"]\n",
    "    grad_time = grad_descent[\"duration\"]\n",
    "    \n",
    "    new_algo = df[df.algo == algo_name]\n",
    "    new_algo_f1 = new_algo[\"f1_score\"]\n",
    "    new_algo_time = new_algo[\"duration\"]\n",
    "\n",
    "    plt.plot(iters, grad_f1, label=\"backpropagation\", color=\"b\")\n",
    "    plt.plot(iters, new_algo_f1, label=algo_name, color=color)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.savefig(f\"{save_abb}_f1.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(iters, grad_time, label=\"backpropagation\", color=\"b\")\n",
    "    plt.plot(iters, rhc_time, label=algo_name, color=color)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Time (ms)\")\n",
    "    plt.savefig(f\"{save_abb}_duration.png\")    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare algorith with random_hill_climb\n",
      "compare algorith with simulated_annealing\n",
      "compare algorith with genetic_alg\n"
     ]
    }
   ],
   "source": [
    "plotting_algo(selected_algorithm[1], color=\"g\", save_abb=\"rhc\")\n",
    "plotting_algo(selected_algorithm[2], color=\"r\", save_abb=\"sa\")\n",
    "plotting_algo(selected_algorithm[3], color=\"y\", save_abb=\"ghc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradient_descent', 'random_hill_climb', 'simulated_annealing', 'genetic_alg']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_algo_total(algo_list):\n",
    "    grad_descent = df[df.algo == \"gradient_descent\"]\n",
    "    iters = grad_descent[\"steps\"]\n",
    "    grad_f1 = grad_descent[\"f1_score\"]\n",
    "    grad_time = grad_descent[\"duration\"]\n",
    "\n",
    "    rhc = df[df.algo == algo_list[1]]\n",
    "    rhc_f1 = rhc[\"f1_score\"]\n",
    "    rhc_time = rhc[\"duration\"]\n",
    "    \n",
    "    sa = df[df.algo == algo_list[2]]\n",
    "    sa_f1 = sa[\"f1_score\"]\n",
    "    sa_time = sa[\"duration\"]\n",
    "    \n",
    "    ga = df[df.algo == algo_list[3]]\n",
    "    ga_f1 = ga[\"f1_score\"]\n",
    "    ga_time = ga[\"duration\"]\n",
    "\n",
    "    plt.plot(iters, grad_f1, label=\"backpropagation\", color=\"b\")\n",
    "    plt.plot(iters, rhc_f1, label=algo_list[1], color=\"g\")\n",
    "    plt.plot(iters, sa_f1, label=algo_list[2], color=\"r\")\n",
    "    plt.plot(iters, ga_f1, label=algo_list[3], color=\"y\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.savefig(f\"total_f1.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(iters, grad_time, label=\"backpropagation\", color=\"C1\")\n",
    "    plt.plot(iters, rhc_time, label=algo_list[1], color=\"g\")\n",
    "    plt.plot(iters, sa_time, label=algo_list[2], color=\"r\")\n",
    "    plt.plot(iters, ga_time, label=algo_list[3], color=\"y\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Time (ms)\")\n",
    "    plt.savefig(f\"total_duration.png\")    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_algo_total(selected_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
